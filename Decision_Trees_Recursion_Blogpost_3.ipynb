{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please read the blog post, and codealong in this Jupyter notebook. https://towardsdatascience.com/decision-tree-from-scratch-in-python-46e99dfea775                                                                                                   \n",
    "\n",
    "\n",
    "\n",
    "Please refer to \"Recursion\" from https://cr.yp.to/2005-261/bender2/DT.pdf , https://medium.com/greyatom/decision-trees-a-simple-way-to-visualize-a-decision-dc506a403aeb, https://www.ke.tu-darmstadt.de/lehre/archiv/ws0809/mldm/dt.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"Find the best split for a node.\n",
    "        \"Best\" means that the average impurity of the two children, weighted by their\n",
    "        population, is the smallest possible. Additionally it must be less than the\n",
    "        impurity of the current node.\n",
    "        To find the best split, we loop through all the features, and consider all the\n",
    "        midpoints between adjacent training samples as possible thresholds. We compute\n",
    "        the Gini impurity of the split generated by that particular feature/threshold\n",
    "        pair, and return the pair with smallest impurity.\n",
    "        Returns:\n",
    "            best_idx: Index of the feature for best split, or None if no split is found.\n",
    "            best_thr: Threshold to use for the split, or None if no split is found.\n",
    "        \"\"\"\n",
    "        # Need at least two elements to split a node.\n",
    "        m = y.size\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        # Count of each class in the current node.\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "\n",
    "        # Gini of current node.\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        # Loop through all features.\n",
    "        for idx in range(self.n_features_):\n",
    "            # Sort data along selected feature.\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "\n",
    "            # We could actually split the node according to each feature/threshold pair\n",
    "            # and count the resulting population for each class in the children, but\n",
    "            # instead we compute them in an iterative fashion, making this for loop\n",
    "            # linear rather than quadratic.\n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):  # possible split positions\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "\n",
    "                # The Gini impurity of a split is the weighted average of the Gini\n",
    "                # impurity of the children.\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "\n",
    "                # The following condition is to make sure we don't try to split two\n",
    "                # points with identical values for that feature, as it is impossible\n",
    "                # (both have to end up on the same side of a split).\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2  # midpoint\n",
    "\n",
    "        return best_idx, best_thr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://towardsdatascience.com/decision-tree-from-scratch-in-python-46e99dfea775"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
